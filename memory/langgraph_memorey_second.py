import sqlite3
import time
from typing import Annotated, TypedDict, Literal, Dict, List, Any
from langchain_openai import ChatOpenAI
from langchain_core.messages import BaseMessage, SystemMessage, HumanMessage, RemoveMessage, ToolMessage, AIMessage
from langchain_core.tools import tool
from langchain_core.runnables import RunnableConfig
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langgraph.checkpoint.sqlite import SqliteSaver
from langgraph.prebuilt import ToolNode
import concurrent.futures
from typing import List, Dict, Any
import time
from ddgs import DDGS

## --- æ•°æ®åº“ä¸çŠ¶æ€å®šä¹‰ ---
DB_PATH = "ai_memory.db"
workflow_conn = sqlite3.connect(DB_PATH, check_same_thread=False)
checkpointer = SqliteSaver(workflow_conn)

# ç¡®ä¿ç”¨æˆ·è®°å¿†è¡¨å­˜åœ¨
workflow_conn.execute("""
CREATE TABLE IF NOT EXISTS user_memories (
    user_id TEXT NOT NULL,
    memory_id TEXT NOT NULL,
    content TEXT NOT NULL,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    PRIMARY KEY (user_id, memory_id)
)
""")
workflow_conn.commit()

class State(TypedDict):
    messages: Annotated[list[BaseMessage], add_messages]
    summary: str

# --- å·¥å…·å®šä¹‰ ---
@tool
def manage_memory(content: str, action: Literal['upsert', 'delete'], memory_id: str):
    """ç®¡ç†é•¿æœŸäº‹å®è®°å¿†ã€‚ç”¨äºè®°å½•ç”¨æˆ·åå¥½ã€èº«ä»½æˆ–é‡è¦äº‹å®ã€‚"""
    return f"Memory {memory_id} {action}ed."

@tool
def web_search(queries: List[str], max_results: int = 3):
    """
    é«˜æ•ˆçš„ç½‘ç»œæœç´¢å·¥å…·ï¼Œæ”¯æŒå¹¶å‘æŸ¥è¯¢å’Œç»“æœå»é‡ã€‚
    - queries: æœç´¢å…³é”®è¯åˆ—è¡¨ï¼Œå»ºè®®é’ˆå¯¹åŒä¸€ä¸ªé—®é¢˜æä¾› 2-3 ä¸ªä¸åŒä¾§é‡ç‚¹çš„å…³é”®è¯ã€‚
    - max_results: æ¯ä¸ªå…³é”®è¯è¿”å›çš„ç»“æœæ•°é‡ï¼ˆå»ºè®®ä¿æŒåœ¨ 3-5 ä¹‹é—´ï¼‰ã€‚
    """

    def _safe_single_search(query: str, max_retries: int = 2) -> List[Dict[str, Any]]:
        """æ‰§è¡Œå•ä¸ªæœç´¢ï¼Œå¸¦é‡è¯•é€»è¾‘å’ŒåŸºç¡€åçˆ¬å»¶è¿Ÿ"""
        for attempt in range(max_retries + 1):
            try:
                # æ¯æ¬¡æœç´¢ç¨å¾®éšæœºå»¶è¿Ÿï¼Œé™ä½è¢«å°æ¦‚ç‡
                time.sleep(0.2 * (attempt + 1)) 
                with DDGS() as ddgs:
                    # ä½¿ç”¨ list å¼ºè½¬ç”Ÿæˆå™¨ï¼Œæ•è·å¯èƒ½çš„ API é”™è¯¯
                    search_results = list(ddgs.text(query, max_results=max_results))
                    return search_results if search_results else []
            except Exception as e:
                if "Ratelimit" in str(e) and attempt < max_retries:
                    time.sleep(1) # é‡åˆ°é¢‘ç‡é™åˆ¶å¤šç­‰ä¸€ä¼š
                    continue
                print(f"âš ï¸ æœç´¢ '{query}' ç¬¬ {attempt+1} æ¬¡å°è¯•å¤±è´¥: {e}")
        return []

    # 1. ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘æ‰§è¡Œæœç´¢ï¼Œæ˜¾è‘—æå‡é€Ÿåº¦
    all_raw_results = []
    # é™åˆ¶æ€»æœç´¢è¯æ¡æ•°ï¼Œé˜²æ­¢ä»»åŠ¡è¿‡é‡
    active_queries = queries[:3] 
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=len(active_queries)) as executor:
        future_to_query = {executor.submit(_safe_single_search, q): q for q in active_queries}
        for future in concurrent.futures.as_completed(future_to_query):
            all_raw_results.extend(future.result())

    # 2. ç»“æœå»é‡ (åŸºäº URL)
    unique_results = {}
    for res in all_raw_results:
        url = res.get('href')
        if url and url not in unique_results:
            unique_results[url] = res

    # 3. æ ¼å¼åŒ–è¾“å‡º
    if not unique_results:
        return "âŒ è”ç½‘æœç´¢æœªæ‰¾åˆ°ç›¸å…³ç»“æœï¼Œè¯·å°è¯•æ›´æ¢å…³é”®è¯æˆ–ç¨åå†è¯•ã€‚"

    formatted_parts = [f"ğŸŒ è”ç½‘æœç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(unique_results)} æ¡å”¯ä¸€æ¥æºï¼š\n"]
    for i, res in enumerate(unique_results.values(), 1):
        title = res.get('title', 'æ— æ ‡é¢˜')
        snippet = res.get('body', 'æ— æè¿°')
        url = res.get('href', '#')
        
        # é™åˆ¶æ‘˜è¦é•¿åº¦ï¼Œé˜²æ­¢æ’‘çˆ† Token
        clean_snippet = snippet.replace('\n', ' ').strip()[:250]
        
        formatted_parts.append(f"[{i}] {title}")
        formatted_parts.append(f"    å†…å®¹: {clean_snippet}...")
        formatted_parts.append(f"    æ¥æº: {url}\n")

    return "\n".join(formatted_parts)
# ---web èŠ‚ç‚¹é€»è¾‘ ---
llm = ChatOpenAI(
    model="gpt-4o", 
    temperature=0.7, 
    openai_api_base="http://192.168.1.159:7022/v1", 
    openai_api_key="EMPTY",
    streaming=True
)

def call_model_node(state: State, config: RunnableConfig):
    user_id = config["configurable"].get("user_id", "default_user")
    enable_search = config["configurable"].get("enable_search", False)
    
    # ä¿®å¤ SyntaxError: å…ˆåœ¨å¤–éƒ¨å¤„ç†é€»è¾‘ï¼Œé¿å…åœ¨ f-string ä¸­ä½¿ç”¨åæ–œæ 
    cursor = workflow_conn.execute("SELECT memory_id, content FROM user_memories WHERE user_id = ?", (user_id,))
    memories_list = [f"- {r[0]}: {r[1]}" for r in cursor.fetchall()]
    memories_str = "\n".join(memories_list) if memories_list else "æš‚æ— è®°å½•"
    
    system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªå…·å¤‡é•¿æœŸè®°å¿†çš„åŠ©æ‰‹ã€‚
ã€ç”¨æˆ·è®°å¿†ã€‘ï¼š
{memories_str}

1.ä»”ç»†åˆ†æå®Œæ•´çš„æ¶ˆæ¯å†å²ï¼ŒåŒ…æ‹¬æ‰€æœ‰ä¹‹å‰çš„å·¥å…·è°ƒç”¨å’Œå·¥å…·æ‰§è¡Œç»“æœã€‚
2.å¦‚æœæ¶ˆæ¯å†å²ä¸­å·²ç»åŒ…å«ä»»ä½•web_searchå·¥å…·è¿”å›çš„æœç´¢ç»“æœï¼Œè¯·ç»å¯¹ä¸è¦å†æ¬¡è°ƒç”¨web_searchå·¥å…·ï¼Œå¿…é¡»åŸºäºå·²æœ‰çš„æœç´¢ç»“æœç›´æ¥å›ç­”ç”¨æˆ·é—®é¢˜ã€‚
3.åªæœ‰åœ¨æ¶ˆæ¯å†å²ä¸­å®Œå…¨æ²¡æœ‰ç›¸å…³æœç´¢ç»“æœï¼Œä¸”ç”¨æˆ·è¯¢é—®çš„æ˜¯æœ€æ–°ä¿¡æ¯ã€å®æ—¶æ•°æ®ã€æ–°é—»äº‹ä»¶æˆ–ä½ ä¸ç¡®å®šçš„ä¿¡æ¯æ—¶ï¼Œæ‰å¯ä»¥ä½¿ç”¨web_searchå·¥å…·æœç´¢ç›¸å…³å†…å®¹ï¼Œæœç´¢æ—¶è¯·æä¾›ç›¸å…³çš„å…³é”®è¯åˆ—è¡¨ã€‚
4.å›ç­”ç”¨æˆ·é—®é¢˜æ—¶ï¼Œå¿…é¡»ç»“åˆweb_searchå·¥å…·è¿”å›çš„æœç´¢ç»“æœï¼Œå¼•ç”¨æœç´¢åˆ°çš„ç›¸å…³ä¿¡æ¯ã€‚
5.å¤æ‚é—®é¢˜è¯·ä½¿ç”¨ <thinking>æ ‡ç­¾è®°å½•æ€è€ƒã€‚å¦‚æœç”¨æˆ·æåˆ°æ–°ä¸ªäººä¿¡æ¯ï¼Œè¯·è°ƒç”¨ manage_memory å·¥å…·ã€‚
6.è¯·ä¸¥æ ¼ä½¿ç”¨ä¸ç”¨æˆ·æé—®æ—¶å®Œå…¨ç›¸åŒçš„è¯­è¨€æ¥å›ç­”é—®é¢˜ï¼Œç»å¯¹ä¸èƒ½ä½¿ç”¨å…¶ä»–è¯­è¨€ã€‚ä¾‹å¦‚ï¼Œå¦‚æœç”¨æˆ·ç”¨ä¸­æ–‡æé—®ï¼Œå°±å¿…é¡»ç”¨ä¸­æ–‡å›ç­”ï¼›å¦‚æœç”¨æˆ·ç”¨è‹±æ–‡æé—®ï¼Œå°±å¿…é¡»ç”¨è‹±æ–‡å›ç­”ã€‚"""
 
    # åŠ¨æ€ç»‘å®šå·¥å…·
    tools = [manage_memory]
    if enable_search:
        tools.append(web_search)
    
    bound_llm = llm.bind_tools(tools)
    response = bound_llm.invoke([SystemMessage(content=system_prompt)] + state["messages"])
    return {"messages": [response]}

from langchain_core.messages import RemoveMessage, AIMessage, ToolMessage, SystemMessage

def reflect_and_store_node(state: State, config: RunnableConfig):
    """
    è§£æå·¥å…·è°ƒç”¨å¹¶æŒä¹…åŒ–ã€‚
    - å¦‚æœæ˜¯æœç´¢ï¼šä¿æŒæ²‰é»˜ï¼Œä¸åšé¢å¤–å¤„ç†ï¼ˆè®©æµç¨‹è‡ªç„¶æµè½¬å› agentï¼‰
    - å¦‚æœæ˜¯è®°å¿†ï¼šæ‰§è¡Œå…¥åº“ï¼Œå¹¶æŠ¹é™¤æ¶ˆæ¯ç—•è¿¹å®ç°â€œé™é»˜â€
    """
    user_id = config["configurable"].get("user_id", "default_user")
    messages = state["messages"]
    last_msg = messages[-1]
    
    # --- 1. å¤„ç†è®°å¿†å·¥å…· manage_memory ---
    if isinstance(last_msg, ToolMessage) and last_msg.name == "manage_memory":
        # è·å–è§¦å‘è¯¥å·¥å…·çš„ AI æ¶ˆæ¯
        last_ai_msg = messages[-2] if len(messages) >= 2 else None
        
        if isinstance(last_ai_msg, AIMessage) and last_ai_msg.tool_calls:
            for tc in last_ai_msg.tool_calls:
                if tc["name"] == "manage_memory":
                    args = tc["args"]
                    # æ•°æ®åº“æŒä¹…åŒ–
                    if args.get("action") == "upsert":
                        workflow_conn.execute(
                            "INSERT OR REPLACE INTO user_memories (user_id, memory_id, content) VALUES (?, ?, ?)",
                            (user_id, args["memory_id"], args["content"])
                        )
                    elif args.get("action") == "delete":
                        workflow_conn.execute(
                            "DELETE FROM user_memories WHERE user_id = ? AND memory_id = ?",
                            (user_id, args["memory_id"])
                        )
            workflow_conn.commit()

        # æ ¸å¿ƒï¼šä½¿ç”¨ RemoveMessage æŠ¹é™¤è®°å¿†ç›¸å…³çš„æ¶ˆæ¯ï¼Œå®ç°é™é»˜
        # è¿™æ ·å›åˆ° agent èŠ‚ç‚¹æ—¶ï¼Œå®ƒä¸çŸ¥é“è‡ªå·±åˆšåˆšå­˜è¿‡è®°å¿†ï¼Œä¹Ÿå°±ä¸ä¼šå›å¤â€œå·²æ›´æ–°â€
        return {
            "messages": [
                RemoveMessage(id=last_msg.id),     # åˆ é™¤ ToolMessage (è®°å¿†å·¥å…·çš„ç»“æœ)
                RemoveMessage(id=last_ai_msg.id)   # åˆ é™¤ AIMessage (å‘èµ·è®°å¿†è¯·æ±‚çš„é‚£æ¡)
            ]
        }

    # --- 2. å¤„ç†æœç´¢å·¥å…· web_search ---
    # æœç´¢å·¥å…·çš„ç»“æœéœ€è¦è¢«ä¿ç•™ï¼Œå¤§æ¨¡å‹æ‰èƒ½æ ¹æ®ç»“æœå›ç­”é—®é¢˜
    # æˆ‘ä»¬ä¸éœ€è¦åœ¨è¿™é‡Œ append SystemMessageï¼Œå› ä¸ºé‚£ä¼šå¹²æ‰°æ¨¡å‹ï¼Œ
    # åªéœ€è¦è¿”å›ç©ºæ›´æ–°ï¼Œæ¨¡å‹ä¼šçœ‹åˆ°å·²æœ‰çš„ ToolMessage(æœç´¢ç»“æœ) å¹¶è‡ªåŠ¨ç»“åˆã€‚
    return {"messages": []}

def summarize_cleanup_node(state: State):
    """æ¶ˆæ¯æ¸…ç†èŠ‚ç‚¹"""
    if len(state["messages"]) > 10:
        delete_msgs = [RemoveMessage(id=m.id) for m in state["messages"][:-5]]
        return {"messages": delete_msgs}
    return {"messages": []}

# --- æ„å»ºå›¾ ---
def route_after_agent(state: State):
    if state["messages"][-1].tool_calls:
        return "action"
    return "summarize"

workflow = StateGraph(State)
workflow.add_node("agent", call_model_node)
workflow.add_node("action", ToolNode([web_search, manage_memory]))
workflow.add_node("reflect", reflect_and_store_node)
workflow.add_node("summarize", summarize_cleanup_node)

workflow.add_edge(START, "agent")
workflow.add_conditional_edges("agent", route_after_agent)
workflow.add_edge("action", "reflect")
workflow.add_edge("reflect", "agent") 
workflow.add_edge("summarize", END)

app = workflow.compile(checkpointer=checkpointer)

def parse_thinking_content(content: str):
    for s, e in [('<thinking>', '</thinking>'), ('<æ€è€ƒ>', '</æ€è€ƒ>')]:
        if s in content and e in content:
            thinking = content.split(s)[1].split(e)[0]
            answer = content.split(e)[1].strip()
            return thinking, answer
    return "", content

#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import gradio as gr
import time
import sqlite3
from langchain_core.messages import HumanMessage, AIMessage, ToolMessage
from langgraph_memorey_second import app, parse_thinking_content

DB_PATH = "ai_memory.db"

def get_formatted_memories(user_id: str) -> str:
    try:
        # ä½¿ç”¨åªè¯»è¿æ¥é¿å…ä¸å†™äº‹åŠ¡å†²çª
        conn = sqlite3.connect(f"file:{DB_PATH}?mode=ro", uri=True)
        cursor = conn.execute("SELECT memory_id, content FROM user_memories WHERE user_id = ? ORDER BY updated_at DESC", (user_id,))
        rows = cursor.fetchall()
        conn.close()
        return "\n\n".join([f"ğŸ“Œ {r[0]}\n   â”” {r[1]}" for r in rows]) or "ğŸ“­ ç›®å‰æ•°æ®åº“ä¸­æ— è®°å½•ã€‚"
    except Exception as e:
        return f"ğŸ“­ æš‚æ— è®°å¿†è®°å½• ({str(e)})"

def chat_stream_real(user_id: str, user_input: str, history: list, enable_search: bool):
    history = history or []
    history.append({"role": "user", "content": user_input})
    history.append({"role": "assistant", "content": ""})
    
    trace_steps = ["ğŸš€ LangGraph å·¥ä½œæµå¯åŠ¨..."]
    config = {
        "configurable": {
            "user_id": user_id, 
            "thread_id": f"thread_{user_id}", 
            "enable_search": enable_search
        }
    }
    
    yield history, "\n".join(trace_steps), get_formatted_memories(user_id), ""
    
    # è·Ÿè¸ªç´¯ç§¯çš„åŠ©æ‰‹å›ç­”
    accumulated_content = ""

    try:
        # 1. ä½¿ç”¨ stream_mode="messages" è·å–çœŸæ­£çš„ Token çº§æµå¼è¾“å‡º
        for msg, metadata in app.stream(
            {"messages": [HumanMessage(content=user_input)]}, 
            config, 
            stream_mode="messages"  # å…³é”®æ”¹åŠ¨ï¼šåˆ‡æ¢åˆ° messages æ¨¡å¼
        ):
            # 2. ä» metadata ä¸­è·å–èŠ‚ç‚¹ä¿¡æ¯ï¼ˆç”¨äºè¿½è¸ªæ‰§è¡Œè½¨è¿¹ï¼‰
            node_name = metadata.get("langgraph_node")
            if node_name and f"ğŸ“ èŠ‚ç‚¹: {node_name}" not in trace_steps:
                trace_steps.append(f"ğŸ“ èŠ‚ç‚¹: {node_name}")
                yield history, "\n".join(trace_steps), get_formatted_memories(user_id), ""
            
            # 3. å¤„ç†å·¥å…·è°ƒç”¨ï¼ˆagentå†³å®šè°ƒç”¨å·¥å…·æ—¶ï¼‰
            if hasattr(msg, "tool_calls") and msg.tool_calls:
                for tc in msg.tool_calls:
                    tool_name = tc['name']
                    tool_args = tc['args']
                    trace_steps.append(f"ğŸ”§ è§¦å‘å·¥å…·: {tool_name}")
                    
                    # æ˜¾ç¤ºå·¥å…·å‚æ•°è¯¦æƒ…
                    if tool_args:
                        args_str = ", ".join([f"{k}={v}" for k, v in tool_args.items()])
                        trace_steps.append(f"   ğŸ“‹ å‚æ•°: {args_str}")
                    
                    # å¦‚æœæ˜¯ç½‘ç»œæœç´¢ï¼Œç«‹å³ç»™ç”¨æˆ·æ˜¾ç¤ºå¼€å§‹æœç´¢çš„åé¦ˆ
                    if tool_name == "web_search":
                        # æ˜¾ç¤ºå…·ä½“çš„æœç´¢å…³é”®è¯
                        search_queries = tool_args.get("queries", [])
                        if search_queries:
                            query_str = ", ".join(search_queries)
                            history[-1]["content"] = f"ğŸ”§ å¼€å§‹ç½‘ç»œæœç´¢: {query_str}..."
                        else:
                            history[-1]["content"] = "ğŸ”§ å¼€å§‹ç½‘ç»œæœç´¢ç›¸å…³ä¿¡æ¯..."
                        # ç«‹å³è¿”å›åé¦ˆç»™ç”¨æˆ·
                        yield history, "\n".join(trace_steps), get_formatted_memories(user_id), ""
            
            # 4. å¤„ç†å·¥å…·æ‰§è¡Œç»“æœ
            elif isinstance(msg, ToolMessage) and msg.content:
                tool_name = msg.name
                trace_steps.append(f"âœ… å·¥å…· '{tool_name}' æ‰§è¡Œå®Œæˆ")
                
                # å¦‚æœæ˜¯ç½‘ç»œæœç´¢ç»“æœï¼Œç»™ç”¨æˆ·æ˜¾ç¤ºæœç´¢å®Œæˆ
                if tool_name == "web_search":
                    history[-1]["content"] = "ğŸ“Š æœç´¢å®Œæˆï¼Œæ­£åœ¨ç”Ÿæˆå›ç­”..."
                
                # åœ¨è½¨è¿¹ä¸­æ˜¾ç¤ºå·¥å…·è¿”å›çš„ç®€è¦ä¿¡æ¯
                if len(msg.content) > 100:
                    brief_result = msg.content[:100] + "..."
                    trace_steps.append(f"   ğŸ“¤ ç»“æœ(ç®€è¦): {brief_result}")
                else:
                    trace_steps.append(f"   ğŸ“¤ ç»“æœ: {msg.content}")
                
                yield history, "\n".join(trace_steps), get_formatted_memories(user_id), ""
            
            # 5. å¤„ç†æ¨¡å‹å›ç­”çš„å®æ—¶ Tokenï¼ˆçœŸæ­£çš„æµå¼è¾“å‡ºï¼‰
            elif isinstance(msg, AIMessage) and msg.content:
                # è¿‡æ»¤æ‰å·¥å…·è°ƒç”¨äº§ç”Ÿçš„æ¶ˆæ¯ï¼ˆé¿å…ä¹±ç ï¼‰
                if not hasattr(msg, "tool_calls") or not msg.tool_calls:
                    # ä½¿ç”¨è‡ªå·±çš„ç´¯ç§¯å˜é‡æ¥ç¡®ä¿æ­£ç¡®è¿½åŠ 
                    accumulated_content += msg.content
                    history[-1]["content"] = accumulated_content
                    yield history, "\n".join(trace_steps), get_formatted_memories(user_id), ""

        # æœ€ç»ˆå¤„ç†æ€è€ƒå†…å®¹æŠ˜å 
        thinking, final_ans = parse_thinking_content(history[-1]["content"])
        if thinking:
            history[-1]["content"] = f"<details><summary>ğŸ¤” æ€è€ƒè¿‡ç¨‹ (ç‚¹å‡»å±•å¼€)</summary>\n\n{thinking}\n\n</details>\n\n{final_ans}"
        
        trace_steps.append("âœ… å“åº”ç”Ÿæˆå®Œæ¯•")
        yield history, "\n".join(trace_steps), get_formatted_memories(user_id), ""

    except Exception as e:
        error_msg = f"âŒ è¿è¡Œé”™è¯¯: {str(e)}"
        trace_steps.append(error_msg)
        history[-1]["content"] = error_msg
        yield history, "\n".join(trace_steps), get_formatted_memories(user_id), ""

# --- Gradio UI æ„å»º ---
with gr.Blocks(title="AI é•¿æœŸè®°å¿†åŠ©ç†") as demo:
    gr.Markdown("# ğŸ§  LangGraph æ™ºèƒ½è®°å¿†åŠ©æ‰‹\nåŸºäº `app.stream()` æ¨èæ¶æ„å®ç°ã€‚")
    
    with gr.Row():
        with gr.Column(scale=4):
            chatbot = gr.Chatbot(label="å¯¹è¯å†å²", height=500)
            msg_in = gr.Textbox(label="å‘é€æ¶ˆæ¯", placeholder="è¾“å…¥å†…å®¹å¹¶æŒ‰å›è½¦...", container=False)
            with gr.Row():
                send_btn = gr.Button("ğŸ“¤ å‘é€", variant="primary")
                clear_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç©º")
        
        with gr.Column(scale=2):
            u_id = gr.Textbox(label="ç”¨æˆ· ID", value="user_001")
            search_en = gr.Checkbox(label="ğŸ” å¯ç”¨ç½‘ç»œæœç´¢", value=False)
            trace_out = gr.Textbox(label="ğŸ” æ‰§è¡Œè½¨è¿¹ (Trace)", interactive=False, lines=10)
            memo_out = gr.Textbox(label="ğŸ§  é•¿æœŸäº‹å®åº“", interactive=False, lines=12)

    send_btn.click(chat_stream_real, [u_id, msg_in, chatbot, search_en], [chatbot, trace_out, memo_out, msg_in])
    msg_in.submit(chat_stream_real, [u_id, msg_in, chatbot, search_en], [chatbot, trace_out, memo_out, msg_in])
    clear_btn.click(lambda: ([], "", ""), None, [chatbot, trace_out, msg_in])
    demo.load(get_formatted_memories, inputs=[u_id], outputs=[memo_out])

if __name__ == "__main__":
    demo.launch(server_name="0.0.0.0", server_port=8000, theme=gr.themes.Soft())

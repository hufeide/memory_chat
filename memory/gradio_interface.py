#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import sqlite3
import gradio as gr
from typing import List, Tuple, Optional, Dict
from langchain_core.messages import HumanMessage, AIMessage, ToolMessage
from langgraph_memorey import app

DB_PATH = "ai_memory.db"

def get_formatted_memories(user_id: str) -> str:
    try:
        conn = sqlite3.connect(DB_PATH, check_same_thread=False)
        conn.row_factory = sqlite3.Row
        cursor = conn.execute(
            "SELECT memory_id, content FROM user_memories WHERE user_id = ? ORDER BY updated_at DESC", 
            (user_id,)
        )
        rows = cursor.fetchall()
        conn.close()
        if not rows: return "ğŸ“­ ç›®å‰æ•°æ®åº“ä¸­æ— è®°å½•ã€‚"
        return "\n\n".join([f"ğŸ“Œ {r['memory_id']}\n   â”” {r['content']}" for r in rows])
    except Exception as e:
        return f"è¯»å–è®°å¿†å‡ºé”™: {str(e)}"

# --- ä½¿ç”¨å…ƒç»„æ ¼å¼ï¼š[(user, bot), (user, bot)] ---
def chat_stream(user_id: str, user_input: str, history: List[Dict[str, str]]):
    history = history or []
    # åˆå§‹çŠ¶æ€ï¼šç”¨æˆ·è¯´äº†è¯ï¼ŒåŠ©æ‰‹è¿˜åœ¨æ€è€ƒ
    history.append({"role": "user", "content": user_input})
    history.append({"role": "assistant", "content": "ğŸ”„ æ­£åœ¨æ€è€ƒ..."})
    
    trace_steps = []
    config = {"configurable": {"user_id": user_id, "thread_id": f"thread_{user_id}"}}
    input_state = {"messages": [HumanMessage(content=user_input)]}

    yield history, "ğŸš€ å·¥ä½œæµå¯åŠ¨...", get_formatted_memories(user_id), ""

    try:
        for chunk in app.stream(input_state, config, stream_mode="updates"):
            for node_name, node_data in chunk.items():
                trace_steps.append(f"ğŸ“ èŠ‚ç‚¹: {node_name}")
                
                if "messages" in node_data:
                    for msg in node_data["messages"]:
                        if isinstance(msg, AIMessage) and msg.content:
                            # æ›´æ–°æœ€åä¸€é¡¹çš„åŠ©æ‰‹å›å¤
                            history[-1]["content"] = msg.content
                        elif hasattr(msg, "tool_calls") and msg.tool_calls:
                            trace_steps.append(f"ğŸ”§ æå–äº‹å®ä¸­...")
                
                yield history, "\n".join(trace_steps), get_formatted_memories(user_id), ""

        # æ£€æŸ¥æ˜¯å¦ä¾ç„¶æ˜¯åˆå§‹æç¤ºï¼Œè‹¥æ˜¯åˆ™æ›´æ–°
        if history[-1]["content"] == "ğŸ”„ æ­£åœ¨æ€è€ƒ...":
            history[-1]["content"] = "å¤„ç†å®Œæˆã€‚"
        
        yield history, "\n".join(trace_steps), get_formatted_memories(user_id), ""

    except Exception as e:
        history[-1]["content"] = f"âŒ é”™è¯¯: {str(e)}"
        yield history, "\n".join(trace_steps), get_formatted_memories(user_id), ""

# --- ç•Œé¢æ„å»º ---
with gr.Blocks(title="AI é•¿æœŸè®°å¿†åŠ©ç†") as demo:
    gr.Markdown("# ğŸ§  LangGraph é•¿æœŸè®°å¿†æ™ºèƒ½ä½“")
    
    with gr.Row():
        u_id = gr.Textbox(label="ç”¨æˆ· ID", value="user_001")
        
    with gr.Row():
        with gr.Column(scale=3):
            # å½»åº•å»æ‰ type å‚æ•°ï¼Œç¡®ä¿ä»»ä½•ç‰ˆæœ¬éƒ½èƒ½åˆå§‹åŒ–
            chatbot = gr.Chatbot(label="å¯¹è¯å†å²", height=500)
            msg_in = gr.Textbox(label="è¾“å…¥æ¶ˆæ¯", placeholder="è¾“å…¥å†…å®¹...", scale=4)
            send_btn = gr.Button("å‘é€", variant="primary")
        
        with gr.Column(scale=2):
            trace_out = gr.Textbox(label="æ‰§è¡Œè½¨è¿¹", interactive=False, lines=12)
            memo_out = gr.Textbox(label="é•¿æœŸäº‹å®åº“ (SQLite)", interactive=False, lines=15)

    send_btn.click(chat_stream, [u_id, msg_in, chatbot], [chatbot, trace_out, memo_out, msg_in])
    msg_in.submit(chat_stream, [u_id, msg_in, chatbot], [chatbot, trace_out, memo_out, msg_in])
    demo.load(get_formatted_memories, [u_id], [memo_out])

if __name__ == "__main__":
    # å¦‚æœ launch é‡Œçš„ theme è¿˜æŠ¥é”™ï¼Œå¯ä»¥å°è¯•å»æ‰å®ƒ
    demo.launch(server_name="0.0.0.0", server_port=7861)